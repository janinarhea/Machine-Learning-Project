---
title: "Machine Learning Project"
author: "Janina Lazo-Cruz"
date: "December 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(caret)
library(lattice)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)

set.seed(12345)

test <- read.csv("pml-testing.csv")
train <- read.csv("pml-training.csv")
```

## Overview

Using data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants, this report aims to predict how well these participants do the exercise. The "classe" variable below pertains to the manner in which the participants conducted the exercise.

To begin with, cleaning up of the data sets provided must be executed.

```{r cleanup}
p.train <- createDataPartition(train$classe, p=0.7, list=FALSE)
s.train <- train[p.train, ]
s.test <- train[-p.train, ]
nil.var <- nearZeroVar(s.train)
s.train <- s.train[, -nil.var]
s.test <- s.test[, -nil.var]
non <- sapply(s.train, function(x) mean(is.na(x)))>0.95
s.train <- s.train[, non==FALSE]
s.test <- s.test[, non==FALSE]
s.train <- s.train[, -(1:5)]
s.test <- s.test[, -(1:5)]
dim(s.train)
head(s.train)
dim(s.test)
head(s.test)
```


## Correlate the Variables

Before creating any prediction models, the variables must be anaylzed by correlating them with each other. The plot generated by the function below allows to display the highly correlated variables displayed as dark colors.

```{r correlate}
cormat <- cor(s.train[, -54])
corrplot(cormat, order = "FPC", method = "color", type="lower",
         tl.cex=0.7, tl.col=rgb(0, 0, 0))
```

## Random Forest

First prediction model to create is Random Forest. The function below generates a plot, displaying the model's accuracy within the title.

```{r modRF}
set.seed(12345)
control <- trainControl(method="cv", number = 3, verboseIter = FALSE)
RF <- train(classe~., data=s.train, method="rf",
                          trControl=control)
RF$finalModel

predictRF <- predict(RF, newdata=s.test)
confmatRF <- confusionMatrix(predictRF, s.test$classe)
confmatRF

plot(confmatRF$table, col=confmatRF$byClass,
     main=paste("Random Forest: Accuracy=",
                round(confmatRF$overall['Accuracy'],4)))
```

## Decision Trees

Next prediction model to apply is Decision Trees. The function below generates a plot, also displaying the model's accuracy within the title.

```{r modDT}
set.seed(12345)
DT <- rpart(classe~., data=s.train, method="class")
fancyRpartPlot(DT)

predictDT <- predict(DT, newdata=s.test, type="class")
confmatDT <- confusionMatrix(predictDT, s.test$classe)
confmatDT

plot(confmatDT$table, col=confmatDT$byClass,
     main=paste("Decision Tree: Accuracy =",
                round(confmatDT$overall['Accuracy'], 4)))
```

## Generalized Boosted Model

Next prediction model to apply is Decision Trees. The function below generates a plot, also displaying the model's accuracy within the title.

```{r modGBM}
set.seed(12345)
conGBM <- trainControl(method="repeatedcv", number=5, repeats=1)
modfitGBM <- train(classe ~., data=s.train, method="gbm",
                   trControl=conGBM, verbose=FALSE)
modfitGBM$finalModel

predictGBM <- predict(modfitGBM, newdata=s.test)
confmatGBM <- confusionMatrix(predictGBM, s.test$classe)
confmatGBM

plot(confmatGBM$table, col=confmatGBM$byClass,
     main=paste("Generalized Boosted Model: Accuracy =", round(confmatGBM$overall['Accuracy'], 4)))
```

## Final Model to Use

Comparing the three models, RF results to the highest accuracy, and thus, it will be used in predicting the 20 cases.

```{r predict}
pred.test <- predict(RF, newdata=test)
pred.test
```